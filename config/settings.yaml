# ScreenControlAgent Configuration

# Controller mode settings (Unified VLM Brain)
controller:
  mode: "vlm_brain"

  llm:
    model: "gpt-5.2"  # Unified VLM brain model (handles both reasoning and vision)
    max_tokens: 4096

# Agent behavior
agent:
  max_steps: 40
  action_delay: 0.5
  verify_each_step: true
  timeout: 300

# VLM provider settings
vlm:
  provider: "openai"  # "claude" or "openai"

  claude:
    model: "claude-3-haiku-20240307"
    max_tokens: 4096

  openai:
    model: "gpt-4o"
    max_tokens: 4096

# Screen capture settings
screen:
  monitor_index: 1  # 1 = primary monitor
  jpeg_quality: 85
  max_width: 1920
  max_height: 1080

# Execution settings
execution:
  mouse:
    move_duration: 0.3
    fail_safe: true
    human_like: true  # Enable human-like mouse movements (smooth, with easing)
  keyboard:
    typing_interval: 0.05

# Grounding settings (Phase 2 - UIAutomation integration)
grounding:
  enabled: true
  mode: "hybrid"  # visual_only, grounded, hybrid
  confidence_threshold: 0.4
  uia_max_depth: 15
  uia_cache_duration: 0.5

# Memory settings (Phase 3 - 记忆系统)
memory:
  enabled: true
  short_term_context_size: 10  # Number of recent observations to keep
  long_term_storage: "data/memory.json"  # Persistent storage path
  element_cache_ttl: 300.0  # Element cache TTL in seconds

# Task planning settings (Phase 3 - 多步任务规划)
task_planning:
  enabled: true
  auto_decompose: true  # Automatically decompose complex tasks
  max_subtasks: 10  # Maximum subtasks per decomposition

# Error recovery settings (Phase 3 - 错误恢复机制)
error_recovery:
  enabled: true
  max_recovery_attempts: 3  # Max recovery attempts per action

# Separated architecture settings (VLM for perception, LLM for reasoning)
# This can improve performance by using a fast VLM for perception
# and a powerful LLM for reasoning
separated_arch:
  enabled: true  # Set to true to enable separated architecture
  perception_provider: "openai"  # VLM for perception: openai or claude
  perception_model: "gpt-4o"  # VLM for extracting visual info
  reasoning_provider: "claude"  # LLM for reasoning: openai or claude
  reasoning_model: "claude-opus-4-20250514"  # Powerful model for decision making

# Logging settings
logging:
  level: "INFO"
  file: "logs/agent.log"
  save_screenshots: false
  screenshot_dir: "logs/screenshots"
